---
title: "Week 8: Differences among more than two samples"
subtitle:  "Session 1"
date: Spring 2020
output:
  beamer_presentation:
    pandoc_args: !expr paste0(here::here('css', 'beamer.yaml'))
header-includes:
  \input{`r here::here("css", "headers_tikz.tex")`}
---

```{r setup, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
require(knitr)
require(here)
source(here("data", "environment_vars.R"))
knitr::opts_chunk$set(root.dir = here(), error = TRUE)
knitr::opts_knit$set(echo = TRUE, error = TRUE, root.dir = here())
i = 1
```


## iClicker Question `r colorize(i, "blue")` `r i = i + 1`

\begin{enumerate}[A]
\item \texttt{two-sample t-test}
\item \texttt{Mann-Whitney paried test}
\item \texttt{Mann-Whitney U test}
\item \texttt{paired t-test}
\end{enumerate}

\logoSoutheast{`r here::here("slides", "slide_images", "iClicker_logo.png")`}








## Announcements




## This week

Tuesday: Differences between more than two samples: 

- Analysis of Variance (ANOVA) concepts
    - One-way ANOVA
    - Two-way ANOVA
    - Multipe testing


Thursday

- Continue ANOVA concepts
- Statistical analysis of salamanders




# Beyond two groups




## A question!

Having just analyzed some fish counts data in 16 lakes in Massachusetts, Thorsten found a significant 'lake' effect using an ANOVA, i.e., the mean number of fish was not the same in all lakes. 

1. What would Thorsten do to find out *which lakes were different from eachother*?

\begin{enumerate}[\hspace{0.5cm}A.]
  \item[A)] A series of $t$-tests
  \item[B)] A Tukey Honest Significant Difference test 
  \item[C)] A Kruskal-Wallis test
\end{enumerate}




## A question!

I am interested in testing whether there is a significant difference between the population sizes of fish in 30 low salinity lakes and 30 high salinity lakes: 

1. Which statistical test should I use?

\begin{enumerate}[\hspace{0.5cm}A.]
  \item[A)] A $t$-test
  \item[B)] A One-Way ANOVA 
  \item[C)] A Chi-square test
  \item[D)] A Two-Way ANOVA
\end{enumerate}




## A question!

I am interested in testing whether there is a significant difference between the population sizes of fish in 30 low salinity lakes and 30 high salinity lakes: 

2. Which is the test statistic for the test?

\begin{enumerate}[\hspace{0.5cm}A.]
  \item[A)] $t$
  \item[B)] $F$ 
  \item[C)] $r$
  \item[D)] $\chi^2$
\end{enumerate}




## A question!

I am interested in testing whether there is a significant difference between the population sizes of fish in 30 low salinity lakes and 30 high salinity lakes. In fact, I actually sampled 10 large, 10 medium, and 10 small lakes in each of the high and low salinity lakes. I want to explore whether there are differences in population size based on lake salinity and lake size. 

3. Now which statistical test should I use?

\begin{enumerate}[\hspace{0.5cm}A.]
  \item[A)] A $t$-test
  \item[B)] A One-Way ANOVA 
  \item[C)] A Chi-square test
  \item[D)] A Two-Way ANOVA
\end{enumerate}




## A question!

I am interested in testing whether there is a significant difference between the population sizes of fish in 30 low salinity lakes and 30 high salinity lakes. In fact, I actually sampled 10 large, 10 medium, and 10 small lakes in each of the high and low salinity lakes. I want to explore whether there are differences in population size based on lake salinity and lake size. 

4. Now Which is the test statistic for the test?

\begin{enumerate}[\hspace{0.5cm}A.]
  \item[A)] $t$
  \item[B)] $F$ 
  \item[C)] $r$
  \item[D)] $\chi^2$
\end{enumerate}




## Comparing differences - two samples

Two samples:

- Which test do we use?

\pic{-3}{-0.5}{6.5}{`r here("slides", "slide_images", "QM.png")`}
\pic{2}{-1}{5}{`r here("slides", "slide_images", "boxXY.pdf")`}




## Comparing differences - two samples

Two samples:

- the t-test?
- test whether group means differ significantly
- $H_0$: there is no significant difference between the means
- $H_1$: there is a significant difference between the means

\pic{3}{-2.2}{4.5}{`r here("slides", "slide_images", "boxXY.pdf")`}




## Comparing differences - two smaples

Two samples:

- the t-test?
- test whether group means differ significantly
- $H_0$: there is no significant difference between the means
- $H_1$: there is a significant difference between the means

\vspace{0.5cm}

Significance based on:

- t-statistic: $t = \frac{|\bar{x}_a - \bar{x}_b |}{\sqrt{\frac{s^2_a}{n_a}+\frac{s^2_b}{n_b}}}$
- degrees of freedom
- *p*-value

\pic{3}{-2.2}{4.5}{`r here("slides", "slide_images", "boxXY.pdf")`}




## Comparing differences - more than two samples

What about if there are more than 2 samples?

- can you think of any examples?

\pic{0}{-0.6}{7}{`r here("slides", "slide_images", "QM.png")`}




## Comparing multiple groups - examples

Regional differences in salamander abundance:

- comparing multiple populations
- quantify the differences between populations

\pic{0}{-2}{5}{`r here("slides", "slide_images", "ANOVA", "multipop.jpg")`}



## Comparing multiple groups - examples

Plant growth related to available resources (pot size):

- comparing multiple treatments
- quantify the effects of resource availability

\picOver{0}{5}{-2}{3.75}{`r here("slides", "slide_images", "ANOVA", "pot.jpg")`}




## Comparing multiple groups - examples

Plants productivity (dry mass in grams) related to fertilizer treatment

- do our treatments influence biomass production?
- is there a positive effect relative to a control?

\picOver{0}{5.5}{-2.5}{3.1}{`r here("slides", "slide_images", "ANOVA", "pots.png")`}




## Comparing multiple groups - examples

When there are more than 2 groups

- t-test doesn't help
   - need to do all possible pairs
   - time consuming
   - get spurious differences just by chance

\begin{tikzpicture}[overlay]
\node[xshift=-0.79cm,yshift=-3.8cm] (one) at (current page.south) {\includegraphics[height=0.62in]{`r here("slides", "slide_images", "ANOVA", "pots.png")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[yshift=-1.2cm] (one) at (current page) {\includegraphics[height=2in]{`r here("slides", "slide_images", "ANOVA", "plant.pdf")`}};
\end{tikzpicture}




## Comparing multiple groups - ANOVA

Analysis of Variance (ANOVA):

- statistical test for testing for differences among >2 groups
- ANOVA and t-test are identical when there are 2 groups
- one factor/group/category (*One-way ANOVA*)

\begin{tikzpicture}[remember picture,overlay]
\node[yshift=-2.4cm] (one) at (current page) {\includegraphics[height=2in]{`r here("slides", "slide_images", "ANOVA", "plant.pdf")`}};
\end{tikzpicture}




## Comparing multiple groups - ANOVA

Analysis of Variance (ANOVA):

- statistical test for testing for differences among >2 groups
- ANOVA and t-test are identical when there are 2 groups
- one factor/group/category (*One-way ANOVA*)

Assumption:

- data are normally distributed

\begin{tikzpicture}[remember picture,overlay]
\node[yshift=-2.4cm] (one) at (current page) {\includegraphics[height=2in]{`r here("slides", "slide_images", "ANOVA", "plant.pdf")`}};
\end{tikzpicture}




## Comparing multiple groups - ANOVA

Analysis of Variance (ANOVA):

- statistical test for testing for differences among >2 groups
- ANOVA and t-test are identical when there are 2 groups
- one factor/group/category (*One-way ANOVA*)

Assumption:

- data are normally distributed

Hypotheses:

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=2cm] at (current page.south)
{\includegraphics[height=1in]{`r here("slides", "slide_images", "QM.png")`}};
\end{tikzpicture}




## Comparing multiple groups - ANOVA

Analysis of Variance (ANOVA):

- statistical test for testing for differences among >2 groups
- ANOVA and t-test are identical when there are 2 groups
- one factor/group/category (*One-way ANOVA*)

Assumption:

- data are normally distributed

Hypotheses:

- $H_0$: there are no significant differences between the means
    - all means are equal
- $H_1$: there are significant differences between the means
    - all means are not equal




## ANOVA explained

The ANOVA partitions the *total* variation into *within* sample variation with *between* sample variation to determine whether samples come from a single distribution or not.


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-1cm] at (current page)
{\includegraphics[height=2.25in]{`r here("slides", "slide_images", "varbox.pdf")`}};
\end{tikzpicture}

## ANOVA and the Sums of Squares

- *Total* sums of squares ($SS_T$)

$$SS_T = \sum(x - \bar{x})^2$$

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=2.75in]{`r here("slides", "slide_images", "sst.pdf")`}};
\end{tikzpicture}

## ANOVA and the Sums of Squares

- *Within-sample* sums of squares ($SS_T$)
- add up the within sample SS

$$SS_W = \sum(x_1 - \bar{x}_1)^2 + \sum(x_2 - \bar{x}_2)^2 + \sum(x_3 - \bar{x}_3)^2$$

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=2.75in]{`r here("slides", "slide_images", "ssw.pdf")`}};
\end{tikzpicture}

## ANOVA and the Sums of Squares

- *Within-sample* sums of squares ($SS_T$)
- more generally ($g$ is the number of groups)

$$SS_W = \sum_g \sum_i (x_{ig} - \bar{x}_g)^2$$

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=2.75in]{`r here("slides", "slide_images", "ssw.pdf")`}};
\end{tikzpicture}

## ANOVA and the Sums of Squares

- *Between-sample* sums of squares ($SS_T$)
- add up the differences in the means

$$SS_B = n_1 (\bar{x}_1 - \bar{x})^2 + n_2 (\bar{x}_2 - \bar{x})^2 + n_3 (\bar{x}_3 - \bar{x})^2$$

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=2.75in]{`r here("slides", "slide_images", "ssb.pdf")`}};
\end{tikzpicture}

## ANOVA and the Sums of Squares

- *Between-sample* sum of squares ($SS_T$)
- more generally ($g$ is the number of groups)

$$SS_B = \sum_g n_g (\bar{x}_g - \bar{x})^2$$

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=2.75in]{`r here("slides", "slide_images", "ssb.pdf")`}};
\end{tikzpicture}

## ANOVA and the Sums of Squares

Total:

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-1cm] at (current page)
{\includegraphics[height=3in]{`r here("slides", "slide_images", "sst.pdf")`}};
\end{tikzpicture}

## ANOVA and the Sums of Squares

Within group:

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-1cm] at (current page)
{\includegraphics[height=3in]{`r here("slides", "slide_images", "ssw.pdf")`}};
\end{tikzpicture}

## ANOVA and the Sums of Squares

Between group:

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-1cm] at (current page)
{\includegraphics[height=3in]{`r here("slides", "slide_images", "ssb.pdf")`}};
\end{tikzpicture}


## ANOVA and the Sums of Squares

\vspace{1cm}

$SS_T = \sum(x - \bar{x})^2$

\vspace{2cm}

$SS_W = \sum_g \sum_i (x_{ig} - \bar{x}_g)^2$

\vspace{2cm}

$SS_B = \sum_g n_g (\bar{x}_g - \bar{x})^2$


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-3cm,yshift=2cm] at (current page.east)
{\includegraphics[height=1.4in]{`r here("slides", "slide_images", "sst.pdf")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-3cm,yshift=-0.5cm] at (current page.east)
{\includegraphics[height=1.4in]{`r here("slides", "slide_images", "ssw.pdf")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-3cm,yshift=-3cm] at (current page.east)
{\includegraphics[height=1.4in]{`r here("slides", "slide_images", "ssb.pdf")`}};
\end{tikzpicture}

## ANOVA degrees of freedom

If we define the following:

- $n$ is the total sample size (number of observations)
- $g$ is the number of groups/samples

## ANOVA degrees of freedom

If we define the following:

- $n$ is the total sample size (number of observations)
- $g$ is the number of groups/samples

Then the degrees of freedom ($df$) are:

- Total: $df_T = n-1$
- Within: $df_W = g-1$
- Between: $df_B = n-g$

## ANOVA the *mean square*

The mean square ($MS$) is the sum of squares divided by the degrees of freedom:

$$MS = SS/df$$

So:

- Total: $MS_T = SS_T/df_T$
- Within: $MS_W = SS_W/df_W$
- Between: $MS_B = SS_B/df_B$

## ANOVA all the ingredients

\vfill

\begin{center}
\renewcommand{\arraystretch}{1.8}
\begin{tabular}{|llll|}
\hline
        & $SS$ & $df$ & $MS$ \\
\hline
Total   & $\sum(x - \bar{x})^2$                  & $n-1$ & $SS_T/df_T$ \\
Within  & $\sum_g \sum_i (x_{ig} - \bar{x}_j)^2$ & $n-g$ & $SS_W/df_W$ \\
Between & $\sum_g n_g (\bar{x}_g - \bar{x})^2$   & $g-1$ & $SS_B/df_B$ \\
\hline
\end{tabular}
\end{center}

\vfill

## ANOVA the statistical test

ANOVA results are usually presented in an ANOVA table

\begin{center}
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{lccccc}
\toprule
Source of variation & $SS$   & $df$   & $MS$   & $F$ & $p$ \\
\hline
Between             & $SS_B$ & $df_B$ & $MS_B$ &           \\
Within              & $SS_W$ & $df_W$ & $MS_W$ &           \\
Total               & $SS_T$ & $df_T$ &   --   &           \\
\bottomrule
\end{tabular}
\end{center}

## ANOVA the statistical test

ANOVA results are usually presented in an ANOVA table

\begin{center}
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{lccccc}
\toprule
Source of variation & $SS$   & $df$   & $MS$   & $F$ & $p$ \\
\hline
Between             & $SS_B$ & $df_B$ & $MS_B$ &           \\
Within              & $SS_W$ & $df_W$ & $MS_W$ &           \\
Total               & $SS_T$ & $df_T$ &   --   &           \\
\bottomrule
\end{tabular}
\end{center}

- $F$ is the test statistic for the ANOVA

$$F = \frac{MS_B}{MS_W}$$

## ANOVA the statistical test

ANOVA results are usually presented in an ANOVA table

\begin{center}
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{lccccc}
\toprule
Source of variation & $SS$   & $df$   & $MS$   & $F$ & $p$ \\
\hline
Between             & $SS_B$ & $df_B$ & $MS_B$ &           \\
Within              & $SS_W$ & $df_W$ & $MS_W$ &           \\
Total               & $SS_T$ & $df_T$ &   --   &           \\
\bottomrule
\end{tabular}
\end{center}

- $p$ is the probability of observing the $F$ statistic with a given degrees of freedom if the null hypothesis is true:
    - null hypothesis is 'no difference between the means'
    - based on the $F$-distribution

## ANOVA the $F$ distribution

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-0.5cm] at (current page)
{\includegraphics[height=3in]{`r here("slides", "slide_images", "F.pdf")`}};
\end{tikzpicture}




## ANOVA the $F$ distribution

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-0.5cm] at (current page)
{\includegraphics[height=3in]{`r here("slides", "slide_images", "F.pdf")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=1cm,yshift=1cm,minimum size = 3pt] at (current page)
{\LARGE $F = \frac{MS_B}{MS_W}$};
\end{tikzpicture}

## ANOVA and the Sums of Squares

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=1.5cm] at (current page)
{\includegraphics[height=1.5in]{`r here("slides", "slide_images", "ssb.pdf")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-0.2cm,minimum size = 3pt] at (current page)
{\LARGE $F = \frac{MS_B}{MS_W}$};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=1.5in]{`r here("slides", "slide_images", "ssw.pdf")`}};
\end{tikzpicture}

## ANOVA and the Sums of Squares

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=1.5cm] at (current page)
{\includegraphics[height=1.5in]{`r here("slides", "slide_images", "ssbA.pdf")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-0.2cm,minimum size = 3pt] at (current page)
{\LARGE $F = \frac{MS_B}{MS_W}$};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=1.5in]{`r here("slides", "slide_images", "sswA.pdf")`}};
\end{tikzpicture}

## ANOVA the $p$ value

Hypotheses:

- $H_0$: there are no significant differences between the means
    - all means are equal
- $H_1$: there are significant differences between the means
    - all means are not equal

When do we reject or fail to reject the null hypothesis?

## ANOVA the $p$ value

Hypotheses:

- $H_0$: there are no significant differences between the means
    - all means are equal
- $H_1$: there are significant differences between the means
    - all means are not equal

When do we reject or fail to reject the null hypothesis?

- if $F$ is large, then $p$ is small
- if $p<0.05$ we reject the null hypothesis
- if $p>0.05$ we *fail to* reject the null hypothesis

## Pairwise comparisons with ANOVA

The $F$ statistic tells us whether there are differences, but *not* what the differences are:

- *Cannot* use *t*-tests to make pairwise comparisons
    - multiple *t*-tests will lead to significant results by chance

## Pairwise comparisons with ANOVA

The $F$ statistic tells us whether there are differences, but *not* what the differences are:

- Instead we conduct *Post-hoc* testing
    - Tukey Honest Significant Difference test (Tukey HSD)
    - accounts for multiple tests being conducted
    - calculation of a *t*-statistic
    - a pair, so degrees of freedom is 1
    - 5% critical value for $df=1$ is 4.303
        - if $t>4.303$ then $p<0.05$

## Pairwise comparisons with ANOVA

The $F$ statistic tells us whether there are differences, but *not* what the differences are:

- Instead we conduct *Post-hoc* testing
    - Tukey Honest Significant Difference test (Tukey HSD)
    - accounts for multiple tests being conducted
    - calculation of a *t*-statistic
    - a pair, so degrees of freedom is 1
    - 5% critical value for $df=1$ is 4.303
        - if $t>4.303$ then $p<0.05$

$$t_{a,b} = \frac{|\bar{x}_a - \bar{x}_b|}{\sqrt{\frac{MS_W \bigg(\frac{1}{n_a}+\frac{1}{n_b}\bigg)}{2}}}$$


## Pairwise comparisons with ANOVA

The $F$ statistic tells us whether there are differences, but *not* what the differences are:

- Instead we conduct *Post-hoc* testing
    - Tukey Honest Significant Difference test (Tukey HSD)
    - accounts for multiple tests being conducted
    - calculation of a *t*-statistic
    - a pair, so degrees of freedom is 1
    - 5% critical value for $df=1$ is 4.303
        - if $t>4.303$ then $p<0.05$

|    |  A  |  B  |  C  |
|----|:---:|:---:|:---:|
| A  |  -  | $t_{A,B}$ | $t_{A,C}$ |
| B  |  -  | -   | $t_{B,C}$ |
| C  |  -  | - | - |



## ANOVA Recap

Comparing differences between >2 samples (groups) using ANOVA

- null hypothesis:
    - no difference between the samples
    - data are from the same population
- alternative hypothesis:
    - sample means are different
    - data from the different populations


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-3cm,yshift=-3cm] at (current page)
{\includegraphics[height=1.8in]{`r here("slides", "slide_images", "anovaNULL.pdf")`}};
\node[xshift=3cm,yshift=-3cm] at (current page)
{\includegraphics[height=1.8in]{`r here("slides", "slide_images", "anovaALT.pdf")`}};
\end{tikzpicture}

## ANOVA Recap

Comparing differences between >2 groups using ANOVA

\begin{center}
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{lccccc}
\toprule
Source of variation & $SS$   & $df$   & $MS$   & $F$                 & $p$ \\
\hline
Between             & $SS_B$ & $df_B$ & $MS_B$ & $\frac{MS_B}{MS_W}$ &     \\
Within              & $SS_W$ & $df_W$ & $MS_W$ &                     &     \\
Total               & $SS_T$ & $df_T$ &   --   &                     &     \\
\bottomrule
\end{tabular}
\end{center}


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-3cm,yshift=-3cm] at (current page)
{\includegraphics[height=1.8in]{`r here("slides", "slide_images", "anovaNULL.pdf")`}};
\node[xshift=3cm,yshift=-3cm] at (current page)
{\includegraphics[height=1.8in]{`r here("slides", "slide_images", "anovaALT.pdf")`}};
\end{tikzpicture}

## ANOVA Recap

Comparing differences between >2 groups using ANOVA

- Essentially comes down to:
    - a model with one mean *or* a model with a mean per group
    - which model best explains the data
    - which model \underline{significantly} reduces the sums of squares


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-3cm,yshift=-3cm] at (current page)
{\includegraphics[height=1.8in]{`r here("slides", "slide_images", "sswC.pdf")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=3cm,yshift=-3cm] at (current page)
{\includegraphics[height=1.8in]{`r here("slides", "slide_images", "sswD.pdf")`}};
\end{tikzpicture}


## More than one factor with ANOVA

So far we have looked at multiple levels within a single factor

- factor: a single categorical predictor variable
- level: the categories within a factor

In some cases, we may be interested in >1 factor

- 2 factors: *two-way* ANOVA
- 3 factors: *three-way* ANOVA
- $\cdots$ multi-way ANOVA

## Two-way ANOVA

Let's use a grazing example:

\begin{center}
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{lcc}
\hline
           & \multicolumn{2}{c}{Site}  \\
\cline{2-3}
Grazing Treatment & Top     & Lower    \\
\hline
Lo                &  9      &  7       \\
Lo                & 11      &  6       \\
Lo                &  6      &  5       \\
Mid               & 14      &  14      \\
Mid               & 17      &  17      \\
Mid               & 19      &  15      \\
Hi                & 28      &  44      \\
Hi                & 31      &  38      \\
Hi                & 32      &  37      \\
\hline
\end{tabular}
\end{center}


## Two-way ANOVA

Lets use the example from the book (in `R` looks like this):

```{r}
graze
```

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=20cm,yshift=-1cm] at (current page)
{\includegraphics[height=2.2in]{`r here("slides", "slide_images", "twoway.pdf")`}};
\end{tikzpicture}

## Two-way ANOVA

Lets use the example from the book (in `R` looks like this):

```{r}
graze
```

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=3.5cm,yshift=-1cm] at (current page)
{\includegraphics[height=2.2in]{`r here("slides", "slide_images", "twoway.pdf")`}};
\end{tikzpicture}

## Two-way ANOVA

Lets use the example from the book (in `R` looks like this):

```{r}
graze
```

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=3.5cm,yshift=-1cm] at (current page)
{\includegraphics[height=2.2in]{`r here("slides", "slide_images", "twowaypt.pdf")`}};
\end{tikzpicture}

## Conducting the ANOVA

\vfill

Step one:

- SS for each factor
    - graze
    - site
- $SS_{graze} = \sum(x_{i,graze} - \bar{x}_{graze})^2$
- Ignore site grouping

\vfill


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=3.5cm,yshift=-1cm] at (current page)
{\includegraphics[height=2.2in]{`r here("slides", "slide_images", "twowayptA.pdf")`}};
\end{tikzpicture}

## Conducting the ANOVA

\vfill

Step one:

- SS for each factor
    - graze
    - site
- $SS_{site} = \sum(x_{i,site} - \bar{x}_{site})^2$
- Ignore graze grouping

\vfill


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=3.5cm,yshift=-1cm] at (current page)
{\includegraphics[height=2.2in]{`r here("slides", "slide_images", "twowayptB.pdf")`}};
\end{tikzpicture}

## Conducting the ANOVA

\vfill

Step two:

- SS for each combinations of factors
- Treat all groupings as unique
- $SS_{within} = (x_{i,g} - \bar{x}_{g})^2$

\vfill


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=3.5cm,yshift=-1cm] at (current page)
{\includegraphics[height=2.2in]{`r here("slides", "slide_images", "twowayptC.pdf")`}};
\end{tikzpicture}

## Conducting the ANOVA

\vfill

Step three:

- Sums of squares of both factors
- $SS_{both} = SS_{total} - SS_{graze} - SS{site} - SS_{within}$

\vfill


## Conducting the ANOVA

\vfill

Step four:

- Total sums of squares
- $SS_{total} = \sum(x_{i} - \bar{x})^2$
- the *null* model
- Ignore all group structure

\vfill


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=3.5cm,yshift=-1cm] at (current page)
{\includegraphics[height=2.2in]{`r here("slides", "slide_images", "twowayptD.pdf")`}};
\end{tikzpicture}

## Conducting the ANOVA - sums of squares

\vfill

\begin{center}
\renewcommand{\arraystretch}{1.4}
\scalebox{0.8}{
\begin{tabular}{llllll}
\toprule
                            & $SS$           & $df$ & $MS$ & $F$ & $p$ \\ \hline
Graze                       & $SS_{graze}$   &      &      &     &     \\
Site                        & $SS_{site}$    &      &      &     &     \\
Both factors(interaction)   & $SS_{both}$    &      &      &     &     \\
Within group                & $SS_{within}$  &      &      &     &     \\
Total                       & $SS_{total}$   &      &      &     &     \\
\bottomrule
\end{tabular}
}
\end{center}

\vfill

## Degrees of freedom

In general:

- Factor 1 (F1): number of levels - 1
- Factor 2 (F2): number of levels - 1
- Within: $n$ - (levels in F1 $\times$ levels in F2)
- Total: $n$ - 1

## Degrees of freedom

In general:

- Factor 1 (F1): number of levels - 1
- Factor 2 (F2): number of levels - 1
- Within: $n$ - (levels in F1 $\times$ levels in F2)
- Total: $n$ - 1

\vspace{0.5cm}

Grazing example:

- Graze: $3-1=2$
- Site: $2-1=1$
- Within: $18 - (3 \times 2) = 12$
- Total: $18 - 1 = 17$

## Degrees of freedom

In general:

- Factor 1 (F1): number of levels - 1
- Factor 2 (F2): number of levels - 1
- Within: $n$ - (levels in F1 $\times$ levels in F2)
- Total: $n$ - 1

\begin{center}
\renewcommand{\arraystretch}{1.4}
\scalebox{0.8}{
\begin{tabular}{llllll}
\toprule
         & $SS$           & $df$          & $MS$   & $F$                 & $p$ \\
\hline
Graze            & $SS_{graze}$   & $df_{graze}$  &        &                     &     \\
Site                    & $SS_{site}$    & $df_{site}$   &        &                     &     \\
Both factors(interaction)   & $SS_{both}$    & $df_{both}$   &        &                     &     \\
Within group                & $SS_{within}$  & $df_{within}$ &        &                     &     \\
Total                       & $SS_{total}$   & $df_{total}$  &        &                     &     \\
\bottomrule
\end{tabular}
}
\end{center}

## Mean squares

- the mean squares are calculated by dividing the sums of squares by the degrees of freedom for each element

\vspace{1.2cm}

\begin{center}
\renewcommand{\arraystretch}{1.4}
\scalebox{0.8}{
\begin{tabular}{llllll}
\toprule
         & $SS$           & $df$          & $MS$                                          & $F$                              & $p$ \\
\hline
Graze                    & $SS_{graze}$   & $df_{graze}$  & $MS_{graze}=\frac{SS_{graze}}{df_{graze}}$    &   &     \\
Site                    & $SS_{site}$    & $df_{site}$   & $MS_{site}=\frac{SS_{site}}{df_{site}}$       &    &     \\
Both factors                & $SS_{both}$    & $df_{both}$   & $MS_{both}=\frac{SS_{both}}{df_{both}}$       &    &     \\
Within group                & $SS_{within}$  & $df_{within}$ & $MS_{within}=\frac{SS_{within}}{df_{within}}$ &                                  &     \\
Total                       & $SS_{total}$   & $df_{total}$  &                                               &                                  &     \\
\bottomrule
\end{tabular}
}
\end{center}

## F statistic

- the $F$-statistic is calculated by taking the element of interest divided by the within group MS (the *error* term)

\vspace{1.2cm}
\begin{center}
\renewcommand{\arraystretch}{1.4}
\scalebox{0.8}{
\begin{tabular}{llllll}
\toprule
        & $SS$           & $df$          & $MS$                                          & $F$                              & $p$ \\
\hline
Graze            & $SS_{graze}$   & $df_{graze}$  & $MS_{graze}=\frac{SS_{graze}}{df_{graze}}$    & $\frac{MS_{graze}}{MS_{within}}$ &     \\
Site                    & $SS_{site}$    & $df_{site}$   & $MS_{site}=\frac{SS_{site}}{df_{site}}$       & $\frac{MS_{site}}{MS_{within}}$  &     \\
Both factors                & $SS_{both}$    & $df_{both}$   & $MS_{both}=\frac{SS_{both}}{df_{both}}$       & $\frac{MS_{both}}{MS_{within}}$  &     \\
Within group                & $SS_{within}$  & $df_{within}$ & $MS_{within}=\frac{SS_{within}}{df_{within}}$ &                                  &     \\
Total                       & $SS_{total}$   & $df_{total}$  &                                               &                                  &     \\
\bottomrule
\end{tabular}
}
\end{center}

## ANOVA the $F$ distribution


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-0.5cm] at (current page)
{\includegraphics[height=3in]{`r here("slides", "slide_images", "FFF.pdf")`}};
\end{tikzpicture}


## ANOVA in practice - R

- Read in the data as a data frame

```{r}
graze
```

## Any ANOVA in practice - R

- Conduct *any* test using formula syntax

```{r}
oneway.site <- aov(Abundance ~ Site, data = graze)
summary(oneway.site)
```

## Any ANOVA in practice - R

- Conduct *any* test using formula syntax

```{r}
oneway.site <- aov(Abundance ~ Site, data = graze)
summary(oneway.site)
```

<!-- \begin{tikzpicture}[remember picture,overlay] -->
<!-- \node[xshift=0cm,yshift=-2.5cm] at (current page) -->
<!-- {\includegraphics[height=1.2in]{SiteExcel4.png}}; -->
<!-- \end{tikzpicture} -->

## Any ANOVA in practice - R

- Conduct *any* test using formula syntax

```{r}
oneway.graze <- aov(Abundance ~ graze, data = graze)
summary(oneway.graze)
```

## Any ANOVA in practice - R

- Conduct *any* test using formula syntax

```{r}
oneway.graze <- aov(Abundance ~ graze, data = graze)
summary(oneway.graze)
```

<!-- \begin{tikzpicture}[remember picture,overlay] -->
<!-- \node[xshift=0cm,yshift=-2.5cm] at (current page) -->
<!-- {\includegraphics[height=1.2in]{GrazeExcel4.png}}; -->
<!-- \end{tikzpicture} -->

## Any ANOVA in practice - R

- Conduct *any* test using formula syntax

```{r}
twoway.additive <- aov(Abundance ~ Site + graze, data = graze)
summary(twoway.additive)
```

## Any ANOVA in practice - R

- Conduct *any* test using formula syntax

```{r}
twoway.additive <- aov(Abundance ~ Site + graze, data = graze)
summary(twoway.additive)
```

\normalsize

<!-- - Excel only *fits* the interaction model -->

## Any ANOVA in practice - R

- Conduct *any* test using formula syntax

```{r}
twoway.interaction <- aov(Abundance ~ Site * graze, data = graze)
summary(twoway.interaction)
```

## Any ANOVA in practice - R

- Conduct *any* test using formula syntax

```{r}
twoway.interaction <- aov(Abundance ~ Site * graze, data = graze)
summary(twoway.interaction)
```

<!-- \begin{tikzpicture}[remember picture,overlay] -->
<!-- \node[xshift=0cm,yshift=-2.5cm] at (current page) -->
<!-- {\includegraphics[height=1.2in]{TWExcel5.png}}; -->
<!-- \end{tikzpicture} -->

## Group Exercise - *salamANOVA*

We will conduct three analyses using the *salamANOVA*. We are interested in whether salamander snout-to-vent length (SVL) varies by sex and/or site. The data look like this:

```{r}
str(sals)
```

\normalsize

- `Site`: there are four sites (`P1A`, `P1B`, `P2A`, `P2B`)
- `Sex`: `M` (male) and `F` (female)
- `SVL`: the snout-to-vent length in mm

## Group Exercise - *salamANOVA*

Analysis 1: Does SVL vary by sex?

- What is the null hypothesis?
- Make a plot to visualize the hypothesis.
- What statistical test will you use to test $H_0$?
- What is the:
    - test statistic for this particulat test (e.g., $t$, $F$, etc)
    - degrees of freedom (calculate this)
    - significance level
- Conduct the analysis:
    - what is the value of the test statistic
    - what the $p$-value
- Write a short paragraph reporting the conclusion, use values from the statistical test to suppo, supported by the results from the test.

## Group Exercise - *salamANOVA*

Analysis 2: Does SVL vary by site?

- What is the null hypothesis?
- Make a plot to visualize the hypothesis.
- What statistical test will you use to test $H_0$?
- What is the:
    - test statistic for this particulat test (e.g., $t$, $F$, etc)
    - degrees of freedom (calculate this)
    - significance level
- Conduct the analysis:
    - what is the value of the test statistic
    - what the $p$-value
- Write a short paragraph reporting the conclusion, use values from the statistical test to suppo, supported by the results from the test.

## Group Exercise - *salamANOVA*

Analysis 3: Does SVL vary by sex and/or site?

- What is the null hypothesis?
- Make a plot to visualize the hypothesis.
- What statistical test will you use to test $H_0$?
- What is the:
    - test statistic for this particulat test (e.g., $t$, $F$, etc)
    - degrees of freedom (calculate this)
    - significance level
- Conduct the analysis:
    - what is the value of the test statistic
    - what the $p$-value
- Write a short paragraph reporting the conclusion, use values from the statistical test to suppo, supported by the results from the test.


## Group Exercise - *salamANOVA*

Assignment: Statistical analysis of variation in salamnder SVL.

- Write a report with four sections:
    1. Analysis 1
    2. Analysis 2
    3. Analysis 3
    4. Reflection: how does analysis 3 compare to analyses 1 and 2?
- Sections 1 to 3 sould report on each of the prompts in the previous slides.
- Section 4 is an opportunity to demonstrate your undertanding of the material covered over the previous weeks.
- Assignment due: 11.55pm Tuesday November 20$^th$