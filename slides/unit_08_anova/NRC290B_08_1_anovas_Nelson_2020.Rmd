---
title: "Week 8: Differences among more than two samples"
subtitle:  "Session 1"
date: Spring 2020
output:
  beamer_presentation:
    pandoc_args: !expr paste0(here::here('css', 'beamer.yaml'))
header-includes:
  \input{`r here::here("css", "headers_tikz.tex")`}
---

```{r setup, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
require(knitr)
require(here)
source(here("data", "environment_vars.R"))
knitr::opts_chunk$set(root.dir = here(), error = TRUE)
knitr::opts_knit$set(echo = TRUE, error = TRUE, root.dir = here())
i = 1
graze <- data.frame(graze= factor(rep(rep(c("Lo","Mid","Hi"),each=3),2),
                                  levels=c("Lo","Mid","Hi")),
                    Site = factor(rep(c("Top","Lower"),each=9), 
                                  levels=c("Lower","Top")),
                    Abundance = c(9,11,6,14,17,19,28,31,32,
                                  7,6,5,14,17,15,44,38,37))
```


## iClicker Question `r colorize(i, "blue")` `r i = i + 1`

I want to compare fish weights in three lakes.  I've sampled 32 fishes from each lake.

What statistical analysis should I perform?

\begin{enumerate}[A]
\item \texttt{Multiple linear regression}
\item \texttt{t-test}
\item \texttt{one-way ANOVA}
\item \texttt{Chi-square test}
\end{enumerate}

\logoSoutheast{`r here::here("slides", "slide_images", "iClicker_logo.png")`}




## iClicker Question `r colorize(i, "blue")` `r i = i + 1`

I want to compare fish weights in two lakes.  I've sampled 32 fishes from each lake.

What statistical analysis should I perform?

\begin{enumerate}[A]
\item \texttt{Multiple linear regression}
\item \texttt{t-test}
\item \texttt{one-way ANOVA}
\item \texttt{Chi-square test}
\end{enumerate}

\logoSoutheast{`r here::here("slides", "slide_images", "iClicker_logo.png")`}





## Announcements

Update to week 8 assignment

This week's material builds on ideas from pairwise group comparisons.

The ANOVA material is more *dense* than what we've covered up until this point.

We're going to have to work on our *statistical intuition* to master these *inferential statistics* concepts.






## This week

Tuesday: Differences between more than two samples: 

- Analysis of Variance (ANOVA) concepts
    - One-way ANOVA
    - Two-way ANOVA
    - Multipe testing

Thursday

- Continue ANOVA concepts
- Statistical analysis of salamanders




## Moving beyond two groups

T-tests are great, but what if we need to analyze more complicated scenarios?

Let's walk through some sampling and experimental scenarios to build intuition.


Scenario context: We're interested in bluegill population densities in Massachusetts lakes.




\begin{tikzpicture}[remember picture,overlay]
\node[yshift = 2.9cm] at (current page.south)
{\includegraphics[height = 2.5cm]{`r here("slides", "slide_images", "bluegill.jpg")`}};
\end{tikzpicture}

\footnotetext[1]{Image credit: New York Fish and Game Commission}



```{r, include = FALSE, echo = FALSE}
i = 1
```



## Scenario `r colorize(i, "black")`

Having just analyzed some fish counts data in 16 lakes in Massachusetts, Thorsten found a significant 'lake' effect using an ANOVA, i.e., the mean number of fish was not the same in all lakes. 

1. Thorsten wants to know which *which lakes are different from each other*.
    - Think carefully: what does this actually mean? 
    - What is the sampling unit?
    - What did he measure?
    - What would he need to compare?



## Scenario `r colorize(i, "black")`

Having just analyzed some fish counts data in 16 lakes in Massachusetts, Thorsten found a significant 'lake' effect using an ANOVA, i.e., the mean number of fish was not the same in all lakes. 

2. What would Thorsten do to find out *which lakes were different from eachother*?

\begin{enumerate}[\hspace{0.5cm}A.]
  \item[A)] A series of $t$-tests
  \item[B)] A Tukey Honest Significant Difference test 
  \item[C)] A Kruskal-Wallis test
\end{enumerate}



`r i = i + 1`
## Scenario `r colorize(i, "black")`

I am interested in testing whether there is a significant difference between the population sizes of fish in 30 **low salinity** lakes and 30 **high salinity** lakes: 

1.  What is different from the last scenario?
2.  What is the sampling unit?
3.  What specific question(s) should I ask?
4.  What, specifically, do I want to compare?





## Scenario `r colorize(i, "black")`

I am interested in testing whether there is a significant difference between the population sizes of fish in 30 **low salinity** lakes and 30 **high salinity** lakes: 

5. Which statistical test could I use?

\begin{enumerate}[\hspace{0.5cm}A.]
  \item[A)] A $t$-test
  \item[B)] A One-Way ANOVA 
  \item[C)] A Chi-square test
  \item[D)] A Two-Way ANOVA
\end{enumerate}

6. Which is the test statistic for the test I chose?




`r i = i + 1`
## Scenario `r colorize(i, "black")`

I am interested in testing whether there is a significant difference between the population density of fish in 30 **low salinity** lakes and 30 **high salinity** lakes. 

In fact, I actually sampled 10 **large**, 10 **medium**, and 10 **small** lakes in each of the high and low salinity lakes. 

I want to explore whether there are differences in population size based on lake **salinity** and lake **size**. 

1. How has our sampling scheme changed?
2. What is the sampling unit?
3. How has our question changed?



## Scenario `r colorize(i, "black")`

I am interested in testing whether there is a significant difference between the population density of fish in 30 **low salinity** lakes and 30 **high salinity** lakes. 

In fact, I actually sampled 10 **large**, 10 **medium**, and 10 **small** lakes in each of the high and low salinity lakes. 

I want to explore whether there are differences in population size based on lake **salinity** and lake **size**. 

4.  Now which statistical test should I use?

\begin{enumerate}[\hspace{0.5cm}A.]
  \item[A)] A $t$-test
  \item[B)] A One-Way ANOVA 
  \item[C)] A Chi-square test
  \item[D)] A Two-Way ANOVA
\end{enumerate}

5.  Now which is the test statistic for the test?




## Comparing differences - two samples

Two samples:

- Which test do we use?

\pic{-3}{-0.5}{6.5}{`r here("slides", "slide_images", "QM.png")`}
\pic{2}{-1}{5}{`r here("slides", "slide_images", "boxXY.pdf")`}




## Comparing differences - two samples

Two samples:

- the t-test?
- test whether group means differ significantly
- $H_0$: there is no significant difference between the means
- $H_1$: there is a significant difference between the means

\pic{3}{-2.2}{4.5}{`r here("slides", "slide_images", "boxXY.pdf")`}




## Comparing differences - two smaples

Two samples:

- the t-test?
- test whether group means differ significantly
- $H_0$: there is no significant difference between the means
- $H_1$: there is a significant difference between the means

\vspace{0.5cm}

Significance based on:

- t-statistic: $t = \frac{|\bar{x}_a - \bar{x}_b |}{\sqrt{\frac{s^2_a}{n_a}+\frac{s^2_b}{n_b}}}$
- degrees of freedom
- *p*-value

\pic{3}{-2.2}{4.5}{`r here("slides", "slide_images", "boxXY.pdf")`}




## Comparing differences - more than two samples

What about if there are more than 2 samples?

- can you think of any examples?

\pic{0}{-0.6}{7}{`r here("slides", "slide_images", "QM.png")`}




## Comparing multiple groups - examples

Regional differences in salamander abundance:

- comparing multiple populations
- quantify the differences between populations

\pic{0}{-2}{5}{`r here("slides", "slide_images", "ANOVA", "multipop.jpg")`}



## Comparing multiple groups - examples

Plant growth related to available resources (pot size):

- comparing multiple treatments
- quantify the effects of resource availability

\picOver{0}{5}{-2}{3.75}{`r here("slides", "slide_images", "ANOVA", "pot.jpg")`}




## Comparing multiple groups - examples

Plants productivity (dry mass in grams) related to fertilizer treatment

- do our treatments influence biomass production?
- is there a positive effect relative to a control?

\picOver{0}{5.5}{-2.5}{3.1}{`r here("slides", "slide_images", "ANOVA", "pots.png")`}




## Comparing multiple groups - examples

When there are more than 2 groups

- t-test is probably not optimal:
   - We would need to do all possible pairs.
   - We might get spurious differences just by chance.  Why?

\begin{tikzpicture}[overlay]
\node[xshift=-0.79cm,yshift=-3.8cm] (one) at (current page.south) {\includegraphics[height=0.62in]{`r here("slides", "slide_images", "ANOVA", "pots.png")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[yshift=-1.2cm] (one) at (current page) {\includegraphics[height=2in]{`r here("slides", "slide_images", "ANOVA", "plant.pdf")`}};
\end{tikzpicture}




## Comparing multiple groups - ANOVA

Analysis of Variance (ANOVA):

- statistical test for testing for differences among >2 groups
- ANOVA and t-test are identical when there are 2 groups
- one factor/group/category (*One-way ANOVA*)

\begin{tikzpicture}[remember picture,overlay]
\node[yshift=-2.4cm] (one) at (current page) {\includegraphics[height=2in]{`r here("slides", "slide_images", "ANOVA", "plant.pdf")`}};
\end{tikzpicture}




## Comparing multiple groups - ANOVA

Analysis of Variance (ANOVA):

- statistical test for testing for differences among >2 groups
- ANOVA and t-test are identical when there are 2 groups
- one factor/group/category (*One-way ANOVA*)

Assumption:

- data are normally distributed

\begin{tikzpicture}[remember picture,overlay]
\node[yshift=-2.4cm] (one) at (current page) {\includegraphics[height=2in]{`r here("slides", "slide_images", "ANOVA", "plant.pdf")`}};
\end{tikzpicture}




## Comparing multiple groups - ANOVA

Analysis of Variance (ANOVA):

- statistical test for testing for differences among >2 groups
- ANOVA and t-test are identical when there are 2 groups
- one factor/group/category (*One-way ANOVA*)

Assumption:

- data are normally distributed

Hypotheses:

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=2cm] at (current page.south)
{\includegraphics[height=1in]{`r here("slides", "slide_images", "QM.png")`}};
\end{tikzpicture}




## Comparing multiple groups - ANOVA

Analysis of Variance (ANOVA):

- statistical test for testing for differences among >2 groups
- ANOVA and t-test are identical when there are 2 groups
- one factor/group/category (*One-way ANOVA*)

Assumption:

- data are normally distributed

Hypotheses:

- $H_0$: there are no significant differences between the means
    - all means are equal
- $H_1$: there are significant differences between the means
    - all means are not equal




## ANOVA explained

The ANOVA partitions the *total* variation into *within* sample (group) variation with *between* sample (group) variation to determine whether samples come from a single distribution or not.


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-1cm] at (current page)
{\includegraphics[height=2.25in]{`r here("slides", "slide_images", "varbox.pdf")`}};
\end{tikzpicture}




## ANOVA and the Sums of Squares

- *Total* sums of squares ($SS_T$)

$$SS_T = \sum(x - \bar{x})^2$$

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=2.75in]{`r here("slides", "slide_images", "sst.pdf")`}};
\end{tikzpicture}




## ANOVA and the Sums of Squares

- *Within-sample* sums of squares ($SS_W$)
- add up the within sample SS

$$SS_W = \sum(x_1 - \bar{x}_1)^2 + \sum(x_2 - \bar{x}_2)^2 + \sum(x_3 - \bar{x}_3)^2$$

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=2.75in]{`r here("slides", "slide_images", "ssw.pdf")`}};
\end{tikzpicture}




## ANOVA and the Sums of Squares

- *Within-sample* sums of squares ($SS_W$)
- more generally ($g$ is the number of groups)

$$SS_W = \sum_g \sum_i (x_{ig} - \bar{x}_g)^2$$

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=2.75in]{`r here("slides", "slide_images", "ssw.pdf")`}};
\end{tikzpicture}




## ANOVA and the Sums of Squares

- *Between-sample* sums of squares ($SS_B$)
- add up the differences in the means

$$SS_B = n_1 (\bar{x}_1 - \bar{x})^2 + n_2 (\bar{x}_2 - \bar{x})^2 + n_3 (\bar{x}_3 - \bar{x})^2$$

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=2.75in]{`r here("slides", "slide_images", "ssb.pdf")`}};
\end{tikzpicture}




## ANOVA and the Sums of Squares

- *Between-sample* sum of squares ($SS_B$)
- more generally ($g$ is the number of groups)

$$SS_B = \sum_g n_g (\bar{x}_g - \bar{x})^2$$

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=2.75in]{`r here("slides", "slide_images", "ssb.pdf")`}};
\end{tikzpicture}




## ANOVA and the Sums of Squares

Total:

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-1cm] at (current page)
{\includegraphics[height=3in]{`r here("slides", "slide_images", "sst.pdf")`}};
\end{tikzpicture}




## ANOVA and the Sums of Squares

Within group:

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-1cm] at (current page)
{\includegraphics[height=3in]{`r here("slides", "slide_images", "ssw.pdf")`}};
\end{tikzpicture}




## ANOVA and the Sums of Squares

Between group:

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-1cm] at (current page)
{\includegraphics[height=3in]{`r here("slides", "slide_images", "ssb.pdf")`}};
\end{tikzpicture}




## ANOVA and the Sums of Squares

\vspace{1cm}

$SS_T = \sum(x - \bar{x})^2$

\vspace{2cm}

$SS_W = \sum_g \sum_i (x_{ig} - \bar{x}_g)^2$

\vspace{2cm}

$SS_B = \sum_g n_g (\bar{x}_g - \bar{x})^2$


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-3cm,yshift=2cm] at (current page.east)
{\includegraphics[height=1.4in]{`r here("slides", "slide_images", "sst.pdf")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-3cm,yshift=-0.5cm] at (current page.east)
{\includegraphics[height=1.4in]{`r here("slides", "slide_images", "ssw.pdf")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-3cm,yshift=-3cm] at (current page.east)
{\includegraphics[height=1.4in]{`r here("slides", "slide_images", "ssb.pdf")`}};
\end{tikzpicture}




## ANOVA degrees of freedom

If we define the following:

- $n$ is the total sample size (number of observations)
- $g$ is the number of groups/samples




## ANOVA degrees of freedom

If we define the following:

- $n$ is the total sample size (number of observations)
- $g$ is the number of groups/samples

Then the degrees of freedom ($df$) are:

- Total: $df_T = n-1$
- Within: $df_W = g-1$
- Between: $df_B = n-g$





## ANOVA the *mean square*

The mean square ($MS$) is the sum of squares divided by the degrees of freedom:

$$MS = SS/df$$

So:

- Total: $MS_T = SS_T/df_T$
- Within: $MS_W = SS_W/df_W$
- Between: $MS_B = SS_B/df_B$




## ANOVA all the ingredients

\vfill

\begin{center}
\renewcommand{\arraystretch}{1.8}
\begin{tabular}{|llll|}
\hline
        & $SS$ & $df$ & $MS$ \\
\hline
Total   & $\sum(x - \bar{x})^2$                  & $n-1$ & $SS_T/df_T$ \\
Within  & $\sum_g \sum_i (x_{ig} - \bar{x}_j)^2$ & $n-g$ & $SS_W/df_W$ \\
Between & $\sum_g n_g (\bar{x}_g - \bar{x})^2$   & $g-1$ & $SS_B/df_B$ \\
\hline
\end{tabular}
\end{center}

\vfill




## ANOVA the statistical test

ANOVA results are usually presented in an ANOVA table

<!-- \begin{center} -->
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{lccccc}
\toprule
Source of variation & $SS$   & $df$   & $MS$   & $F$ & $p$ \\
\hline
Between             & $SS_B$ & $df_B$ & $MS_B$ &           \\
Within              & $SS_W$ & $df_W$ & $MS_W$ &           \\
Total               & $SS_T$ & $df_T$ &   --   &           \\
\bottomrule
\end{tabular}
<!-- \end{center} -->




## ANOVA the statistical test

ANOVA results are usually presented in an ANOVA table

<!-- \begin{center} -->
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{lccccc}
\toprule
Source of variation & $SS$   & $df$   & $MS$   & $F$ & $p$ \\
\hline
Between             & $SS_B$ & $df_B$ & $MS_B$ &           \\
Within              & $SS_W$ & $df_W$ & $MS_W$ &           \\
Total               & $SS_T$ & $df_T$ &   --   &           \\
\bottomrule
\end{tabular}
<!-- \end{center} -->

- $F$ is the test statistic for the ANOVA

$$F = \frac{MS_B}{MS_W}$$





## ANOVA the statistical test

ANOVA results are usually presented in an ANOVA table

<!-- \begin{center} -->
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{lccccc}
\toprule
Source of variation & $SS$   & $df$   & $MS$   & $F$ & $p$ \\
\hline
Between             & $SS_B$ & $df_B$ & $MS_B$ &           \\
Within              & $SS_W$ & $df_W$ & $MS_W$ &           \\
Total               & $SS_T$ & $df_T$ &   --   &           \\
\bottomrule
\end{tabular}
<!-- \end{center} -->

- $p$ is the probability of observing the $F$ statistic with a given degrees of freedom if the null hypothesis is true:
    - null hypothesis is 'no difference between the means'
    - based on the $F$-distribution




## ANOVA the $F$ distribution

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-0.5cm] at (current page)
{\includegraphics[height=3in]{`r here("slides", "slide_images", "F.pdf")`}};
\end{tikzpicture}




## ANOVA the $F$ distribution

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-0.5cm] at (current page)
{\includegraphics[height=3in]{`r here("slides", "slide_images", "F.pdf")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=1cm,yshift=1cm,minimum size = 3pt] at (current page)
{\LARGE $F = \frac{MS_B}{MS_W}$};
\end{tikzpicture}




## ANOVA and the Sums of Squares

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=1.5cm] at (current page)
{\includegraphics[height=1.5in]{`r here("slides", "slide_images", "ssb.pdf")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-0.2cm,minimum size = 3pt] at (current page)
{\LARGE $F = \frac{MS_B}{MS_W}$};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=1.5in]{`r here("slides", "slide_images", "ssw.pdf")`}};
\end{tikzpicture}




## ANOVA and the Sums of Squares

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=1.5cm] at (current page)
{\includegraphics[height=1.5in]{`r here("slides", "slide_images", "ssbA.pdf")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-0.2cm,minimum size = 3pt] at (current page)
{\LARGE $F = \frac{MS_B}{MS_W}$};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=0cm,yshift=-2.5cm] at (current page)
{\includegraphics[height=1.5in]{`r here("slides", "slide_images", "sswA.pdf")`}};
\end{tikzpicture}




## ANOVA the $p$ value

Hypotheses:

- $H_0$: there are no significant differences between the means
    - all means are equal
- $H_1$: there are significant differences between the means
    - all means are not equal

When do we reject or fail to reject the null hypothesis?




## ANOVA the $p$ value

Hypotheses:

- $H_0$: there are no significant differences between the means
    - all means are equal
- $H_1$: there are significant differences between the means
    - all means are not equal

When do we reject or fail to reject the null hypothesis?

- if $F$ is large, then $p$ is small
- if $p<0.05$ we reject the null hypothesis
- if $p>0.05$ we *fail to* reject the null hypothesis




## Pairwise comparisons with ANOVA

The $F$ statistic tells us whether there are differences, but *not* what the differences are:

- *Cannot* use *t*-tests to make pairwise comparisons
    - multiple *t*-tests will lead to significant results by chance




## Pairwise comparisons with ANOVA

The $F$ statistic tells us whether there are differences, but *not* what the differences are:

- Instead we conduct *Post-hoc* testing
    - Tukey Honest Significant Difference test (Tukey HSD)
    - accounts for multiple tests being conducted
    - calculation of a *t*-statistic
    - a pair, so degrees of freedom is 1
    - 5% critical value for $df=1$ is 4.303
        - if $t>4.303$ then $p<0.05$




## Pairwise comparisons with ANOVA

The $F$ statistic tells us whether there are differences, but *not* what the differences are:

- Instead we conduct *Post-hoc* testing
    - Tukey Honest Significant Difference test (Tukey HSD)
    - accounts for multiple tests being conducted
    - calculation of a *t*-statistic
    - a pair, so degrees of freedom is 1
    - 5% critical value for $df=1$ is 4.303
        - if $t>4.303$ then $p<0.05$

$$t_{a,b} = \frac{|\bar{x}_a - \bar{x}_b|}{\sqrt{\frac{MS_W \bigg(\frac{1}{n_a}+\frac{1}{n_b}\bigg)}{2}}}$$




## Pairwise comparisons with ANOVA

The $F$ statistic tells us whether there are differences, but *not* what the differences are:

- Instead we conduct *Post-hoc* testing
    - Tukey Honest Significant Difference test (Tukey HSD)
    - accounts for multiple tests being conducted
    - calculation of a *t*-statistic
    - a pair, so degrees of freedom is 1
    - 5% critical value for $df=1$ is 4.303
        - if $t>4.303$ then $p<0.05$

|    |  A  |  B  |  C  |
|----|:---:|:---:|:---:|
| A  |  -  | $t_{A,B}$ | $t_{A,C}$ |
| B  |  -  | -   | $t_{B,C}$ |
| C  |  -  | - | - |





## ANOVA Recap

Comparing differences between >2 samples (groups) using ANOVA

- null hypothesis:
    - no difference between the samples
    - data are from the same population
- alternative hypothesis:
    - sample means are different
    - data from the different populations


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-3cm,yshift=-3cm] at (current page)
{\includegraphics[height=1.6in]{`r here("slides", "slide_images", "anovaNULL.pdf")`}};
\node[xshift=3cm,yshift=-3cm] at (current page)
{\includegraphics[height=1.6in]{`r here("slides", "slide_images", "anovaALT.pdf")`}};
\end{tikzpicture}




## ANOVA Recap

Comparing differences between >2 groups using ANOVA

<!-- \begin{center} -->
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{lccccc}
\toprule
Source of variation & $SS$   & $df$   & $MS$   & $F$                 & $p$ \\
\hline
Between             & $SS_B$ & $df_B$ & $MS_B$ & $\frac{MS_B}{MS_W}$ &     \\
Within              & $SS_W$ & $df_W$ & $MS_W$ &                     &     \\
Total               & $SS_T$ & $df_T$ &   --   &                     &     \\
\bottomrule
\end{tabular}
<!-- \end{center} -->


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-3cm,yshift=-3cm] at (current page)
{\includegraphics[height=1.6in]{`r here("slides", "slide_images", "anovaNULL.pdf")`}};
\node[xshift=3cm,yshift=-3cm] at (current page)
{\includegraphics[height=1.6in]{`r here("slides", "slide_images", "anovaALT.pdf")`}};
\end{tikzpicture}




## ANOVA Recap

Comparing differences between >2 groups using ANOVA

- Essentially comes down to:
    - a model with one mean *or* a model with a mean per group
    - which model best explains the data
    - which model \underline{significantly} reduces the sums of squares


\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-3cm,yshift=-3cm] at (current page)
{\includegraphics[height=1.8in]{`r here("slides", "slide_images", "sswC.pdf")`}};
\end{tikzpicture}

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=3cm,yshift=-3cm] at (current page)
{\includegraphics[height=1.8in]{`r here("slides", "slide_images", "sswD.pdf")`}};
\end{tikzpicture}




## More than one factor with ANOVA

So far we have looked at multiple levels within a single factor

- factor: a single categorical predictor variable
- level: the categories within a factor

In some cases, we may be interested in >1 factor

- 2 factors: *two-way* ANOVA
- 3 factors: *three-way* ANOVA
- $\cdots$ multi-way ANOVA

